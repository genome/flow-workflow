#!/usr/bin/env python

from redis import Redis
import argparse
from flow.orchestrator.types import DataNode
import flow_workflow.workflowxml as wfxml
import json
import os
import pika
import pwd
import subprocess
import sys
import tempfile

if __name__ == "__main__":
    redis_url = os.getenv("FLOW_REDIS_URL")
    amqp_url = os.getenv("AMQP_URL")
    if not redis_url:
        print "Environment variable FLOW_REDIS_URL not defined!"
        sys.exit(1)

    if not redis_url:
        print "Environment variable AMQP_URL not defined!"
        sys.exit(1)

    uid = os.getuid()
    user_name = pwd.getpwuid(uid).pw_name

    parser = argparse.ArgumentParser(description="Submit a workflow to be run")
    parser.add_argument('xml', help="A valid workflow xml file")
    parser.add_argument('inputs', help="A json file containing the workflow inputs")
    parser.add_argument('--block', default=False, action="store_true",
                        help="Block until the workflow is finished")
    parser.add_argument('--outputs-file', default=None,
                        help="Store workflow outputs in the given file "
                             "(implies --block)")

    args = parser.parse_args()
    conn = Redis(redis_url)

    if args.outputs_file:
        args.block = True

    xml = open(args.xml).read()
    input_str = open(args.inputs).read()
    flow_inputs = json.loads(input_str)

    model = wfxml.convert_workflow_xml(xml)
    flow = model.node(conn, None)
    flow.user_id = uid
    flow.environment = os.environ.data
    flow.working_directory = os.getcwd()
    print "Submitting workflow", str(flow.key)

    dn = DataNode.create(connection=conn,
                         outputs=flow_inputs,
                         name="Inputs for %s" % flow.name.value)

    flow.input_connections = { dn.key: {} }

    routing_key = "flow.node.execute"
    body = json.dumps({
        "node_key": flow.node(0).key,
        "message_class": "ExecuteNodeMessage",
    })

    conn = pika.BlockingConnection(pika.URLParameters(amqp_url))
    qchannel = conn.channel()
    qchannel.exchange_declare(
        exchange="workflow",
        exchange_type="topic",
        durable=True,
        arguments={"alternate-exchange": "workflow.alt"}
        )
    qchannel.basic_publish(
        exchange="workflow",
        routing_key=routing_key,
        body=body,
        properties=pika.BasicProperties(
            delivery_mode=2,
        )
    )

    if args.block:
        print "Waiting for workflow", flow.name
        cmdline = ['wait_for_flow.py', flow.key]
        rv = subprocess.call(cmdline)
        if not flow.status.value:
            print "Flow %s claims completion but status is None" % flow.key
        else:
            print "Completed flow %s: status=%s" % (flow.key, flow.status.value)

        if rv == 0 and args.outputs_file:
            fp = open(args.outputs_file, "w")
            fp.write(json.dumps(flow.outputs.value))
            fp.close()
            print "Outputs written to", args.outputs_file
            print "Outputs were", flow.outputs.value
        print "Workflow wrapper exiting with exit code", rv, sys.argv
        sys.exit(rv)
